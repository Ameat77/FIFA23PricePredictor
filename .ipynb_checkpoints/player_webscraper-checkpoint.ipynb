{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_p1(soup): #Gets basic information such as player name, club, nation, league, age, etc\n",
    "    info_table = soup.find(\"table\", {\"class\" : \"table table-info\"})\n",
    "    headers = []\n",
    "    for item in info_table.findAll(\"th\"):\n",
    "        headers.append(item.text.strip())\n",
    "    descriptions = []\n",
    "    count = 0\n",
    "    for j in info_table.findAll(\"tr\"):\n",
    "        des = j.find_all(\"td\")[0].text.strip()\n",
    "        if headers[count].lower() == \"accelerate\": #if we are looking at the accelerate\n",
    "            if des[0] == \"E\":\n",
    "                des = \"Explosive\"\n",
    "            elif des[0] == \"C\":\n",
    "                des = \"Controlled\"\n",
    "            else:\n",
    "                des = \"Lengthy\"\n",
    "        descriptions.append(des)                 \n",
    "        count += 1\n",
    "    return headers, descriptions\n",
    "\n",
    "def get_stats_p2(soup): #Gets player ratings, stats, overall, and position\n",
    "    stats = soup.find(\"div\", {\"id\": \"player_stats_json\"})\n",
    "    stats = stats.text.strip()\n",
    "    stats = json.loads(stats)[0]\n",
    "    categories = [\"Pace\", \"Passing\", \"Shooting\", \"Dribbling\", \"Defending\", \"Physical\"]\n",
    "    values = []\n",
    "    categories.append(\"Overall\")\n",
    "    categories.append(\"Position\")\n",
    "    #This block will get a player's overall and position\n",
    "    values.append((soup.find(\"div\", {\"class\": \"pcdisplay-rat\"}).text))\n",
    "    values.append((soup.find(\"div\", {\"class\": \"pcdisplay-pos\"}).text))\n",
    "    if values[1] == \"GK\":\n",
    "        return get_stats_p2_gk(soup)\n",
    "    for cat in categories:\n",
    "        if (cat.lower() != \"overall\" and cat.lower() != \"position\"):\n",
    "            values.append(stats[cat.lower()][0][\"value\"])\n",
    "    return categories, values\n",
    "\n",
    "def get_stats_p2_gk(soup): #Gets player ratings, stats, overall, and position\n",
    "    stats = soup.find(\"div\", {\"id\": \"player_stats_json\"})\n",
    "    stats = stats.text.strip()\n",
    "    stats = json.loads(stats)[0]\n",
    "    categories = [\"Gkdiving\", \"Gkhandling\", \"Gkkicking\", \"Gkreflexes\", \"Speed\", \"Gkpositioning\"]\n",
    "    values = []\n",
    "    categories.append(\"Overall\")\n",
    "    categories.append(\"Position\")\n",
    "    #This block will get a player's overall and position\n",
    "    values.append((soup.find(\"div\", {\"class\": \"pcdisplay-rat\"}).text))\n",
    "    values.append((soup.find(\"div\", {\"class\": \"pcdisplay-pos\"}).text))\n",
    "    for cat in categories:\n",
    "        if (cat.lower() != \"overall\" and cat.lower() != \"position\"):\n",
    "            values.append(stats[cat.lower()][0][\"value\"])\n",
    "    return categories, values\n",
    "\n",
    "\n",
    "def get_price_data_daily(player_id): #Gets price data on a player and adds it to a csv (for normal players)\n",
    "    response = requests.get(\n",
    "  url='https://proxy.scrapeops.io/v1/',\n",
    "  params={\n",
    "      'api_key': 'ecea4014-8c14-480c-845d-a7ff7ad269ec',\n",
    "      'url': 'https://www.futbin.com/23/playerGraph?player=' + player_id +'&year=23&type=daily_graph', \n",
    "  },\n",
    ")\n",
    "    string = response.content.decode(\"utf-8\")\n",
    "    dic = json.loads(string)\n",
    "    path = \"./Player_Data/\" + player_id\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir(path)\n",
    "    if \"ps\" in dic:\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/psdaily_graphFIFA23.csv\" #Path to csv data\n",
    "        lis = dic[\"ps\"]\n",
    "        time_stamp = []\n",
    "        price = []\n",
    "        for item in lis:\n",
    "            time_stamp.append(item[0])\n",
    "            price.append(item[1])\n",
    "        headers = [\"Unix Time\", \"Price\"]\n",
    "\n",
    "        with open(data_path, 'w', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # write the header\n",
    "            writer.writerow(headers)\n",
    "            for i in range(len(price)):\n",
    "                # write the data\n",
    "                writer.writerow([time_stamp[i], price[i]])\n",
    "    if \"pc\" in dic:\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/pcdaily_graphFIFA23.csv\" #Path to csv data\n",
    "        lis = dic[\"pc\"]\n",
    "        time_stamp = []\n",
    "        price = []\n",
    "        for item in lis:\n",
    "            time_stamp.append(item[0])\n",
    "            price.append(item[1])\n",
    "        headers = [\"Unix Time\", \"Price\"]\n",
    "\n",
    "        with open(data_path, 'w', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # write the header\n",
    "            writer.writerow(headers)\n",
    "            for i in range(len(price)):\n",
    "                # write the data\n",
    "                writer.writerow([time_stamp[i], price[i]])\n",
    "    else:\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/nodata.txt\"\n",
    "        with open(data_path, 'w') as fp:\n",
    "            pass\n",
    "        \n",
    "def get_price_data_yday(player_id): #Gets price data on a player and adds it to a csv (for normal players)\n",
    "    response = requests.get(\n",
    "  url='https://proxy.scrapeops.io/v1/',\n",
    "  params={\n",
    "      'api_key': 'ecea4014-8c14-480c-845d-a7ff7ad269ec',\n",
    "      'url': 'https://www.futbin.com/23/playerGraph?player=' + player_id +'&year=23&type=yesterday', \n",
    "  },\n",
    ")\n",
    "    string = response.content.decode(\"utf-8\")\n",
    "    dic = json.loads(string)\n",
    "    path = \"./Player_Data/\" + player_id\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir(path)\n",
    "    if \"ps\" in dic:\n",
    "        lis = dic[\"ps\"]\n",
    "        dt = datetime.datetime.utcfromtimestamp(int(lis[0][0])/1000)\n",
    "        time = (str(dt)[0:10])\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/\" + time + \"psydaygraphFIFA23.csv\" #Path to csv data\n",
    "        time_stamp = []\n",
    "        price = []\n",
    "        for item in lis:\n",
    "            time_stamp.append(item[0])\n",
    "            price.append(item[1])\n",
    "        headers = [\"Unix Time\", \"Price\"]\n",
    "        with open(data_path, 'w', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # write the header\n",
    "            writer.writerow(headers)\n",
    "            for i in range(len(price)):\n",
    "                # write the data\n",
    "                writer.writerow([time_stamp[i], price[i]])\n",
    "    if \"pc\" in dic:\n",
    "        lis = dic[\"pc\"]\n",
    "        dt = datetime.datetime.utcfromtimestamp(int(lis[0][0])/1000)\n",
    "        time = (str(dt)[0:10])\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/\" + time + \"pcyesterday_graphFIFA23.csv\" #Path to csv data\n",
    "        time_stamp = []\n",
    "        price = []\n",
    "        for item in lis:\n",
    "            time_stamp.append(item[0])\n",
    "            price.append(item[1])\n",
    "        headers = [\"Unix Time\", \"Price\"]\n",
    "        with open(data_path, 'w', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # write the header\n",
    "            writer.writerow(headers)\n",
    "            for i in range(len(price)):\n",
    "                # write the data\n",
    "                writer.writerow([time_stamp[i], price[i]])\n",
    "    else:\n",
    "        data_path = \"./Player_Data/\" + player_id + \"/nodata.txt\"\n",
    "        with open(data_path, 'w') as fp:\n",
    "            pass\n",
    "        \n",
    "                 \n",
    "\n",
    "\n",
    "def get_player_dic(player_link):#Creates a player_dic\n",
    "    r = requests.get(\n",
    "      url='https://proxy.scrapeops.io/v1/',\n",
    "      params={\n",
    "          'api_key': 'ecea4014-8c14-480c-845d-a7ff7ad269ec',\n",
    "          'url': player_link, \n",
    "      },\n",
    "    )\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    results = str(soup.prettify())\n",
    "    actual_id = results[results.find(\"data-player-resource\") + 22: results.find(\"data-position\") - 2]\n",
    "    headers = []\n",
    "    descriptions = []\n",
    "    h1, d1 = get_stats_p1(soup)\n",
    "    h2, d2 = get_stats_p2(soup)\n",
    "    headers = h1 + h2\n",
    "    descriptions = d1 + d2\n",
    "    dic = {}\n",
    "    irrelevant = [\"Origin\", \"Added on\", \"Club ID\", \"League ID\", \"B.Type\", \"R.Face\"]\n",
    "    for i in range(len(headers)):\n",
    "        if headers[i] == \"Height\":\n",
    "            dic[headers[i]] = descriptions[i][:3]\n",
    "        elif headers[i] == \"Age\":\n",
    "            dic[headers[i]] = descriptions[i][:2]\n",
    "        elif headers[i] not in irrelevant:\n",
    "            dic[headers[i]] = descriptions[i]\n",
    "    dic[\"ID\"] = actual_id\n",
    "    player_id = dic[\"ID\"]\n",
    "    path = \"./Player_Data/\" + player_id\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir(path)\n",
    "    with open(\"./Player_Data/\" + player_id + \"/infoFIFA23.txt\", 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dic))\n",
    "    return dic\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "player_links = []\n",
    "#Format of Link to loop through player_dataset: https://www.futbin.com/players?page=1\n",
    "for i in range(100):\n",
    "    r = requests.get(\n",
    "          url='https://proxy.scrapeops.io/v1/',\n",
    "          params={\n",
    "              'api_key': 'ecea4014-8c14-480c-845d-a7ff7ad269ec',\n",
    "              'url': \"https://www.futbin.com/players?page=\" + str(i+1), \n",
    "          },\n",
    "        )\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    player_lis = (soup.findAll(\"tr\", {\"class\": \"player_tr_2\"}))\n",
    "    for item in player_lis:\n",
    "        item = str(item)\n",
    "        string = \"https://www.futbin.com\" + item[item.find(\"data\") + 10: item.find(\">\") - 1]\n",
    "        player_links.append(string)\n",
    "    player_lis = (soup.findAll(\"tr\", {\"class\": \"player_tr_1\"}))\n",
    "    for item in player_lis:\n",
    "        item = str(item)\n",
    "        string = \"https://www.futbin.com\" + item[item.find(\"data\")  + 10: item.find(\">\") - 1]\n",
    "        player_links.append(string)\n",
    "    if (i % 5 == 0):\n",
    "        print(player_links[-10:])\n",
    "with open(\"playerlinks.txt\", 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(player_links))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'AcceleRATE', 'Club', 'Nation', 'League', 'Skills', 'Weak Foot', 'Intl. Rep', 'Foot', 'Height', 'Weight', 'Revision', 'Att. WR', 'Def. WR', 'Added on', 'Origin', 'R.Face', 'B.Type', 'DOB', 'ID', 'Club ID', 'League ID'] ['Lev Yashin', 'Controlled', 'FUT ICONS', 'Russia', 'Icons', '1', '3', '4', 'Right', '189cm | 6\\'2\"', '82', 'Icon', 'Med', 'Med', '2021-08-31', 'Prime', '', 'High & Average', '22-10-1929', '238380', '112658', '2118']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m player_dic[player_id] \u001b[38;5;241m=\u001b[39m dic\n\u001b[1;32m      7\u001b[0m get_price_data_daily(player_id)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_price_data_yday\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mget_price_data_yday\u001b[0;34m(player_id)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_price_data_yday\u001b[39m(player_id): \u001b[38;5;66;03m#Gets price data on a player and adds it to a csv (for normal players)\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m  \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://proxy.scrapeops.io/v1/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapi_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mecea4014-8c14-480c-845d-a7ff7ad269ec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.futbin.com/23/playerGraph?player=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m&year=23&type=yesterday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     string \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m     dic \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(string)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#We are on 18 for i\n",
    "for i in range(18, len(player_links)):\n",
    "    link = player_links[i]\n",
    "    dic = get_player_dic(link)\n",
    "    player_id = dic[\"ID\"]\n",
    "    player_dic[player_id] = dic\n",
    "    get_price_data_daily(player_id)\n",
    "    get_price_data_yday(player_id)\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.futbin.com/23/player/174/lev-yashin'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_links[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code gets the player's price data\n",
    "#Format of Code to get Prices\n",
    "#Hourly Graph (today): https://www.futbin.com/23/playerGraph?type=today&year=23&player=173731\n",
    "#Hourly Graph (yday): https://www.futbin.com/23/playerGraph?type=yesterday&year=23&player=173731\n",
    "#Daily Graph: https://www.futbin.com/23/playerGraph?player=173731&year=23&type=daily_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        writer.writerow([time_stamp[i], price[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, sep=\",\")\n",
    "# shows top 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now we have price data, what's the next plan:\n",
    "'''\n",
    "When in day should I buy a player\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gkdiving': [{'shortcut': 'DIV', 'gk_shortcut': 'DIV', 'chem_change': 1, 'id': 'gkdiving', 'stat_num': 'igs4', 'name': 'Diving', 'gk_stat_name': 'Diving', 'type': 'main', 'value': 95, 'max': True}, {'shortcut': 'DIV', 'chem_change': 1, 'id': 'gkdiving', 'stat_num': 'igs5', 'name': 'Diving', 'type': 'sub', 'value': 95, 'max': True}], 'gkhandling': [{'shortcut': 'HAN', 'gk_shortcut': 'HAN', 'chem_change': 1, 'id': 'gkhandling', 'stat_num': 'igs11', 'name': 'Handling', 'gk_stat_name': 'Handling', 'type': 'main', 'value': 89, 'max': True}, {'shortcut': 'HAN', 'chem_change': 1, 'id': 'gkhandling', 'stat_num': 'igs12', 'name': 'Handling', 'type': 'sub', 'value': 89, 'max': True}], 'gkkicking': [{'shortcut': 'KIC', 'gk_shortcut': 'KIC', 'chem_change': 1, 'id': 'gkkicking', 'stat_num': 'igs18', 'name': 'Kicking', 'gk_stat_name': 'Kicking', 'type': 'main', 'value': 75, 'max': True}, {'shortcut': 'KIC', 'chem_change': 1, 'id': 'gkkicking', 'stat_num': 'igs19', 'name': 'Kicking', 'type': 'sub', 'value': 75, 'max': True}], 'gkreflexes': [{'shortcut': 'REF', 'gk_shortcut': 'REF', 'chem_change': 1, 'id': 'gkreflexes', 'stat_num': 'igs30', 'name': 'Reflexes', 'gk_stat_name': 'Reflexes', 'type': 'main', 'value': 96, 'max': True}, {'shortcut': 'REF', 'chem_change': 1, 'id': 'gkreflexes', 'stat_num': 'igs31', 'name': 'Reflexes', 'type': 'sub', 'value': 96, 'max': True}], 'speed': [{'shortcut': 'SPE', 'gk_shortcut': 'SPE', 'chem_change': 1, 'id': 'speed', 'stat_num': 'igs1', 'name': 'Speed', 'gk_stat_name': 'Speed', 'type': 'main', 'value': 60, 'max': True}, {'shortcut': 'ACC', 'chem_change': 1, 'id': 'acceleration', 'stat_num': 'igs2', 'name': 'Acceleration', 'type': 'sub', 'value': 65, 'max': True}, {'shortcut': 'S/S', 'chem_change': 1, 'id': 'sprintspeed', 'stat_num': 'igs3', 'name': 'Sprint Speed', 'type': 'sub', 'value': 53, 'max': True}], 'gkpositioning': [{'shortcut': 'POS', 'gk_shortcut': 'POS', 'chem_change': 1, 'id': 'gkpositioning', 'stat_num': 'igs24', 'name': 'Positioning', 'gk_stat_name': 'Positioning', 'type': 'main', 'value': 95, 'max': True}, {'shortcut': 'POS', 'chem_change': 1, 'id': 'gkpositioning', 'stat_num': 'igs25', 'name': 'Positioning', 'type': 'sub', 'value': 95, 'max': True}]}\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\n",
    "      url='https://proxy.scrapeops.io/v1/',\n",
    "      params={\n",
    "          'api_key': 'ecea4014-8c14-480c-845d-a7ff7ad269ec',\n",
    "          'url': \"https://www.futbin.com/23/player/174/lev-yashin\", \n",
    "      },\n",
    "    )\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "stats = soup.find(\"div\", {\"id\": \"player_stats_json\"})\n",
    "stats = stats.text.strip()\n",
    "stats = json.loads(stats)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 89, 75, 96, 60, 95, '94', 'GK']\n"
     ]
    }
   ],
   "source": [
    "stats = soup.find(\"div\", {\"id\": \"player_stats_json\"})\n",
    "stats = stats.text.strip()\n",
    "stats = json.loads(stats)[0]\n",
    "categories = [\"Gkdiving\", \"Gkhandling\", \"Gkkicking\", \"Gkreflexes\", \"Speed\", \"Gkpositioning\"]\n",
    "values = []\n",
    "for cat in categories:\n",
    "    values.append(stats[cat.lower()][0][\"value\"])\n",
    "\n",
    "categories.append(\"Overall\")\n",
    "categories.append(\"Position\")\n",
    "#This block will get a player's overall and position\n",
    "values.append((soup.find(\"div\", {\"class\": \"pcdisplay-rat\"}).text))\n",
    "values.append((soup.find(\"div\", {\"class\": \"pcdisplay-pos\"}).text))\n",
    "return categories, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'AcceleRATE', 'Club', 'Nation', 'League', 'Skills', 'Weak Foot', 'Intl. Rep', 'Foot', 'Height', 'Weight', 'Revision', 'Att. WR', 'Def. WR', 'Added on', 'Origin', 'R.Face', 'B.Type', 'DOB', 'ID', 'Club ID', 'League ID'] ['Lev Yashin', 'Controlled', 'FUT ICONS', 'Russia', 'Icons', '1', '3', '4', 'Right', '189cm | 6\\'2\"', '82', 'Icon', 'Med', 'Med', '2021-08-31', 'Prime', '', 'High & Average', '22-10-1929', '238380', '112658', '2118']\n",
      "{'Name': 'Lev Yashin', 'AcceleRATE': 'Controlled', 'Club': 'FUT ICONS', 'Nation': 'Russia', 'League': 'Icons', 'Skills': '1', 'Weak Foot': '3', 'Intl. Rep': '4', 'Foot': 'Right', 'Height': '189', 'Weight': '82', 'Revision': 'Icon', 'Att. WR': 'Med', 'Def. WR': 'Med', 'DOB': '22-10-1929', 'ID': '238380', 'Gkdiving': '94', 'Gkhandling': 'GK', 'Gkkicking': 95, 'Gkreflexes': 89, 'Speed': 75, 'Gkpositioning': 96, 'Overall': 60, 'Position': 95}\n"
     ]
    }
   ],
   "source": [
    "print(get_player_dic(\"https://www.futbin.com/23/player/174/lev-yashin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
